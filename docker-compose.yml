version: "3.7"

# port : 호스트 OS와 컨테이너의 포트를 바인딩 시켜준다.
# expose : 호스트 OS에 포트를 공개하지 않고, 컨테이너만 공개
#    - 호스트 OS에 직접 연결되지 않고 링크등으로 연결된 컨테이너-컨테이너간의 통신만 필요한 경우 사용
# depends_on : 서비스간의 종속성 순서대로 서비스를 시작 
# container_name : 컨테이너 이름을 지정
# volumes : docker 컨테이너의 생명 주기와 관계없이 데이터를 영속적으로 저장

services:
  backend:
    container_name: backend
    # env_file: ./.env
    build: ./backend/.
    volumes:
      - ./backend/:/backend/
      - static_volume:/backend/static # <-- bind the static volume
    stdin_open: true
    tty: true
    command: gunicorn --bind :8000 backend.wsgi:application
    networks:
      - backend_network
    environment:
      - CHOKIDAR_USEPOLLING=true
      - DJANGO_SETTINGS_MODULE=backend.settings

  frontend:
    container_name: wb-frontend
    build: ./frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/:/wb-frontend
      - ./frontend/node_modules/:/wb-frontend/node_modules

  backend-server:
    container_name: nginx-back
    build:
      context: ./nginx/.
      dockerfile: Dockerfile
    volumes:
      - static_volume:/backend/static # <-- bind the static volume
      - ./nginx/log:/var/log/nginx # nginx log path (require same option on nginx container)
    ports:
      - "80:8080"
      - "433:433"
    depends_on:
      - backend
    networks:
      - backend_network

  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - 9090:9090
    volumes:
      - ./prometheus/:/etc/prometheus/
      
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    depends_on:
      - backend
    networks:
      - backend_network
    expose:
      - 9090

  grafana:
    image: grafana/grafana:latest
    ports:
      - 3333:3000
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=grafana
    depends_on:
      - backend
      - prometheus
    volumes:
      - ./data/grafana:/var/lib/grafana
    networks:
      - backend_network

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter # 컨테이너를 stop시키기 전까지 항상 재시작
    restart: unless-stopped
    ports:
      - 9100:9100
    networks:
      - backend_network
  
  # nginx-exporter:
  #   image: nginx/nginx-prometheus-exporter:0.10.0
  #   command:
  #     - -nginx.scrape-uri
  #     - http://127.0.0.1:80/stub_status
  #   ports:
  #     - 9113:9113

  # cadvisor:
  #   image: gcr.io/cadvisor/cadvisor:v0.38.7
  #   container_name: cadvisor
  #   restart: unless-stopped
  #   command:
  #     - '--disable_metrics=hugetlb'
  #     - '--disable_metrics=referenced_memory'
  #   privileged: true
  #   ports:
  #     - 8089:8089
  #   volumes:
  #     - '/:/rootfs:ro'
  #     - '/var/run:/var/run:ro'
  #     - '/sys:/sys:ro'
  #     - '/var/lib/docker/:/var/lib/docker:ro'
  #     - '/dev/disk/:/dev/disk:ro'
  #     - /etc/machine-id:/etc/machine-id:ro
  #   networks:
  #     - backend_network
  #   devices:
  #     - /dev/kmsg:/dev/kmsg

  rabbitmq:
    image: rabbitmq:3.7-management
    container_name: "rabbitmq"
    ports:
      # Expose the port for the worker to add/get tasks
      - 5672:5672
      # OPTIONAL: Expose the GUI port
      - 15672:15672
    expose:
      - 5672
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672//
    depends_on:
      - backend
    networks:
      - backend_network
    tty: true

  celery:
    container_name: celery_service
    build:
      context: ./backend
    volumes:
      - ./backend:/backend
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672//
    command: >
      bash -c "celery -A backend worker --loglevel=info --pool=solo"
    networks:
      - backend_network
    depends_on:
      - rabbitmq
      - backend
    tty: true
  
  elasticsearch:
    build:
      context: ./elk/elasticsearch
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    restart: unless-stopped

  logstash:
    build:
      context: ./elk/logstash
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: changeme
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    build:
      context: ./elk/kibana
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: changeme
    depends_on:
      - elasticsearch
    restart: unless-stopped

  filebeat:
    build:
      context: ./elk/filebeat
      args:
        ELASTIC_VERSION: 8.5.2
    entrypoint: "filebeat -e -strict.perms=false"
    volumes:
      - ./elk/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - ./nginx/log:/var/log/nginx # nginx log path (require same option on nginx container)
    depends_on:
      - logstash
      - elasticsearch
      - kibana

networks:
  backend_network:
    driver: bridge
volumes:
  static_volume:
  # 인스턴스에 대해 데이터를 영구적으로 유지하기 위해 2개의 볼륨 사용
  prometheus_data: {}
  grafana_data: {}
  elasticsearch:
